---
title: "The Application of Machine Learning on Risk Classification of Heart Disease"
author:
  - Xiaoyu Lin
  - Kyoka Ono
output:
  html_document:
    df_print: paged
geometry: margin=1in
---

# Abstract

GitHub Link: <https://github.com/kyokaono8811/biostat625finalproject.git>

Heart disease is a leading cause of death for adults in the U.S, and early detection of key risk factors is essential for prevention.

In this study, we apply multiple machine learning methods, including logistic regression, random forest, GAM, ikNN, XGBoost, and RNN identify the significant risk factors of heart disease. We then evaluate model performance and compare variable importance across methods using evaluation Metrics.

(Some results conclusion)

# Contributions

-   **Xiaoyu Lin** — "Data description, Data cleaning..."\
-   **Kyoka Ono** — "..."

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = TRUE,
  warning = FALSE,
  message = FALSE 
)
```

```{r}
#install.packages("reticulate")
library(reticulate)
```

```{python}
#reticulate::py_install("matplotlib")
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
pd.set_option('future.no_silent_downcasting', True)
```

# Introduction

Heart disease affects millions of individuals in the U.S, making early identification of risk factors a high public-health priority. Traditional statistical approaches have identified several predictors, but machine learning methods can capture more complex, nonlinear relationships.

This project applies several different machine learning algorithms to the `heart_2022_no_nans.csv` dataset from the CDC Behavioral Risk Factor Surveillance System (BRFSS) on Kaggle. Our goal is to determine which model outputs the highest evaluation metric for predicting heart attack, and which variables significantly associated with having had a heart attack?

# Methods

### **Data Source**

The dataset contains 40 variables for over 200,000 survey participants (all complete cases).

```{python}
heart_data = pd.read_csv("data/heart_2022_no_nans.csv")

# first couple rows of the data
heart_data.head()

# Number of participants (rows) and variables (columns)
print("\nNumber of participants:", heart_data.shape[0])
print("Number of variables:", heart_data.shape[1])
```

### **Preprocessing**

**Variable Selection**

We choose 10 covariates out of 40 for our models based on literature review and use `HadHeartAttack` as the predicted variable

```{python}
heart_data = heart_data[[
        "HadHeartAttack",
        "Sex",
        "PhysicalActivities",
        "SleepHours",
        "HadStroke",
        "HadDiabetes",
        "SmokerStatus",
        "RaceEthnicityCategory",
        "AgeCategory",
        "BMI",
        "AlcoholDrinkers"]
]
```

Outcome Variable:

-   `HadHeartAttack`: Binary indicator (Yes/No) of whether a doctor diagnosed the respondent with a heart attack.

Predictor Variables:

-   `Sex`: Biological sex of the participant (Male/Female).

-   `PhysicalActivities`: Whether the participant engaged in physical activities in the past month (Yes/No).

-   `SleepHours`: Average number of hours of sleep per night (numeric).

-   `HadStroke`: Whether had a stroke (Yes/No).

-   `HadDiabetes`: Whether had a diabetes (Yes/No/Yes, but only during pregnancy (female)/No, pre-diabetes or borderline diabetes).

-   `SmokerStatus`: Smoking status of the participant (Former smoker/Never smoked/Current smoker – now smokes every day/Current smoker – now smokes some days/No).

-   `RaceEthnicityCategory`: (White only, Non-Hispanic/Black only, Non-Hispanic/Other race only, Non-Hispanic/Multiracial, Non-Hispanic/Hispanic)

-   `AgeCategory`: Age group (18–24, 25–29, …, 80+).

-   `BMI`: Body mass index (numeric).

-   `AlcoholDrinkers`: Whether a participant is a heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per (Yes/No).

**Data Cleaning**

We would like to create dummy variables for categorical variables and merge equivalent levels.

```{python}
heart_clean = heart_data.copy()

# Binary variables: Yes = 1, No = 0
binary_vars = ["HadHeartAttack", "PhysicalActivities", "HadStroke", "AlcoholDrinkers"]

for var in binary_vars:
    heart_clean[var] = heart_clean[var].map({"Yes": 1, "No": 0})

# Sex: Female = 0, Male = 1
heart_clean["Sex"] = heart_clean["Sex"].map({"Female": 0, "Male": 1})

# AgeCategory: Youngest = 1, Oldest = 13
age_order = [
    "Age 18 to 24",
    "Age 25 to 29",
    "Age 30 to 34",
    "Age 35 to 39",
    "Age 40 to 44",
    "Age 45 to 49",
    "Age 50 to 54",
    "Age 55 to 59",
    "Age 60 to 64",
    "Age 65 to 69",
    "Age 70 to 74",
    "Age 75 to 79",
    "Age 80 or older"
]

# Create dictionary: each age category → number (1 to 13)
age_map = {age: i+1 for i, age in enumerate(age_order)}

heart_clean["AgeCategory"] = heart_clean["AgeCategory"].map(age_map)

# HadDiabetes: Yes = 1, No = 0
heart_clean["HadDiabetes"] = heart_clean["HadDiabetes"].replace({
    "Yes": 1,
    "Yes, but only during pregnancy (female)": 1,
    "No": 0,
    "No, pre-diabetes or borderline diabetes": 0
})

# SmokerStatus: Never smoked = 0, Former smoker = 1, Current smoker = 2
heart_clean["SmokerStatus"] = heart_clean["SmokerStatus"].replace({
    "Never smoked": 0,
    "Former smoker": 1,
    "Current smoker - now smokes every day": 2,
    "Current smoker - now smokes some days": 2
})

# RaceEthnicityCategory: White = 0, Black = 1, Hispanic = 2, Multiracial = 3, Other = 4
heart_clean["RaceEthnicityCategory"] = heart_clean["RaceEthnicityCategory"].replace({
    "White only, Non-Hispanic": 0,    
    "Black only, Non-Hispanic": 1,    
    "Hispanic": 2,                     
    "Multiracial, Non-Hispanic": 3,  
    "Other race only, Non-Hispanic": 4
})
```

### **Data Description**

```{python}
# Variables
categorical_vars = [
    "HadHeartAttack", "Sex", "PhysicalActivities", "HadStroke",
    "HadDiabetes", "SmokerStatus", "RaceEthnicityCategory",
    "AgeCategory", "AlcoholDrinkers"
]

numeric_vars = ["SleepHours", "BMI"]

all_vars = categorical_vars + numeric_vars

# Order of categorical variables
category_orders = {
    "HadHeartAttack": [0, 1],
    "Sex": [0, 1],
    "PhysicalActivities": [0, 1],
    "HadStroke": [0, 1],
    "HadDiabetes": [0, 1],
    "AlcoholDrinkers": [0, 1],
    "SmokerStatus": [0, 1, 2],
    "RaceEthnicityCategory": [0, 1, 2, 3, 4],
    "AgeCategory": list(range(1, 14))
}

# Layout
n_plots = len(all_vars)
n_cols = 3
n_rows = (n_plots + n_cols - 1) // n_cols

fig, axes = plt.subplots(
    n_rows,
    n_cols,
    figsize=(20, 4 * n_rows),
    sharey=False
)

axes = axes.flatten()

for i, col in enumerate(all_vars):
    ax = axes[i]

    # Categorical variables: bar plots
    if col in categorical_vars:
        counts = heart_clean[col].value_counts().reindex(category_orders[col])
        ax.bar(counts.index, counts.values)
        ax.set_xticks(category_orders[col])
        ax.tick_params(axis="x", labelrotation=45, labelsize=9)

    # Numerical variables: histograms
    else:
        ax.hist(heart_clean[col], bins=20)
        ax.tick_params(axis="x", labelrotation=45, labelsize=9)

    ax.set_title(col, fontsize=12)
    ax.tick_params(axis="y", labelsize=9)
    ax.set_xlabel("")
    ax.set_ylabel("")

# Remove empty panels
for j in range(len(all_vars), len(axes)):
    fig.delaxes(axes[j])

# Shared y-axis label
fig.text(0.04, 0.5, "Count", va="center", rotation="vertical", fontsize=12)

# Adjust spacing
plt.subplots_adjust(
    wspace=0.4,  # horizontal space
    hspace=0.6   # vertical space
)
# Save the figure
fig.savefig("graphs/all_variables_plot.png", dpi=300, bbox_inches="tight")

plt.show()
```

From the graph above, we can see that some categorical variables such as `HadHeartAttack`, `HadStroke`, and `RaceEthnicityCategory` exhibit noticeable class imbalance. Highly imbalanced classes may affect model performance if not addressed, so we will use the method of undersampling the majority class during model training. Other categorical variables are more balanced.

Numerical variables like `AgeCategory`, `SleepHours`, and `BMI` show skewed distributions. To improve model performance, these variables should be standardized or centered, especially for algorithms sensitive to scale (e.g. logistic regression).

### **Models Applied**

1.  **Logistic Regression**

2.  

### **Evaluation Metrics**

# Results

# Conclusion

# References

-   Pytlak, K. (n.d.). Personal key indicators of heart disease [Data set]. Kaggle. <https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease/data>

-   Centers for Disease Control and Prevention. (2024, December 2). Heart disease risk factors. <https://www.cdc.gov/heart-disease/risk-factors/?CDC_AAref_Val=https://www.cdc.gov/heartdisease/risk_factors.htm>
